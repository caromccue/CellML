{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e3f5acdb91ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mselect_rectangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_date_taken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen_grey_scale_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegment_droplets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcrop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_indiv_droplets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_processing_overlay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_overlay_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import math\n",
    "import logging\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.data.utils import select_rectangle, get_date_taken, open_grey_scale_image\n",
    "from src.data.segment_droplets import crop, segment, extract_indiv_droplets\n",
    "from src.visualization.image_processing_overlay import save_overlay_image\n",
    "from src.visualization.process_plotting import plot_crystal_data\n",
    "from src.models.utils.loading_models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_path, crop_box, model, save_overlay=False):\n",
    "    '''\n",
    "    Process a single image to obtain the number of droplets with and without crystals\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    imgage_path: string\n",
    "        Path to the image to process\n",
    "    crop_box: (minRow, maxRow, minCol, maxCol)\n",
    "        Cropping box to select the region of interest\n",
    "    model: tensorflow model\n",
    "        Instance of a tensorflow model trained to discriminate droplets containing crystals vs. clear\n",
    "    save_overlay: bool, optional\n",
    "        Save an image with green / red overlays for drops containing crystals / empty to `image_path / overlay`\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (date_take: datetime, num_drops: int, num_clear: int, num_crystal: int)\n",
    "        Date from the EXIF data, number of drops, number of clear drops, number of drops containing crystals\n",
    "    '''\n",
    "    \n",
    "    # Open image\n",
    "    date_taken = get_date_taken(image_path)\n",
    "    image = open_grey_scale_image(image_path)\n",
    "\n",
    "    # Crop image\n",
    "    cropped = crop(image, crop_box)\n",
    "\n",
    "    # Segment image\n",
    "    (labeled, _) = segment(cropped)\n",
    "\n",
    "    # Extract individual droplets\n",
    "    drop_images, regProps = extract_indiv_droplets(cropped, labeled)\n",
    "\n",
    "    # Predict labels from model\n",
    "    if drop_images and len(drop_images) > 0:\n",
    "        X  = np.asarray(drop_images)\n",
    "        Y = model.predict_classes(X).flatten().tolist()\n",
    "\n",
    "        num_drops = len(Y)\n",
    "        num_clear = Y.count(0)\n",
    "        num_crystal = num_drops - num_clear\n",
    "    \n",
    "    else:\n",
    "        logging.warning(\"No droplets found in image %s\", image_path)\n",
    "        num_drops = 0\n",
    "        num_clear = 0\n",
    "        num_crystal = 0\n",
    "\n",
    "    # Save overlay if applicable\n",
    "    if save_overlay:\n",
    "        path = os.path.join(os.path.dirname(image_path), 'overlay', os.path.basename(image_path))\n",
    "        save_overlay_image(path, cropped, regProps, Y)\n",
    "\n",
    "    return (date_taken, num_drops, num_clear, num_crystal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_batch(image_list, crop_box, model_name, batch_number=0, verbosity=logging.WARNING, save_overlay=False):\n",
    "    '''Process a batch of images and return a list of results\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_list: list[string]\n",
    "        List of paths to the image to process\n",
    "    crop_box: (minRow, maxRow, minCol, maxCol)\n",
    "        Cropping box to select the region of interest\n",
    "    model_name: string\n",
    "        Path to the tensorflow model to load\n",
    "    batch_numer: int\n",
    "        Batch number when parallel processing for progress bar display. Default: 0\n",
    "    verbosity: int\n",
    "        verbosity as a logging level. Default: logging.WARNING (30)\n",
    "    save_overlay: bool, optional\n",
    "        Save an image with green / red overlays for drops containing crystals / empty to `image_path / overlay`. Default: False\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[(date_take: datetime, num_drops: int, num_clear: int, num_crystal: int, image_name: string)]\n",
    "        List of extracted parameters for each of the images\n",
    "        Date from the EXIF data, number of drops, number of clear drops, number of drops containing crystals, name of the image\n",
    "    '''\n",
    "\n",
    "    # Instantiate the model\n",
    "    model = load_model(model_name)\n",
    "\n",
    "    # Process the data\n",
    "    data = []\n",
    "    for image_path in tqdm(image_list,\n",
    "                           desc=\"Thread #{}\".format(batch_number),\n",
    "                           position=batch_number,\n",
    "                           leave=(batch_number == 0),\n",
    "                           disable=((batch_number != 0) and (verbosity > 20))\n",
    "                           ):\n",
    "        image_name = os.path.basename(image_path)\n",
    "        data.append(process_image(image_path, crop_box, model, save_overlay=save_overlay) + (image_name,))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_folder(directory, crop_box=None, show_plot=False, save_overlay=False, show_segmentation=False):\n",
    "\n",
    "    # List images in directory\n",
    "    supported_extensions = ['jpg', 'png', 'gif', 'jpeg ', 'eps', 'bmp', 'tiff', 'bmp',\n",
    "                                     'icns', 'ico', 'spi',]\n",
    "    image_list = [os.path.join(directory, image_path) for image_path in os.listdir(directory) if os.path.splitext(image_path)[1][1:].lower() in supported_extensions]\n",
    "\n",
    "    # Define the model path\n",
    "    model_name = \"cnn-simple-model.json\"\n",
    "\n",
    "    # Obtain crop box from user if not passed as argument\n",
    "    while not crop_box:\n",
    "        logging.info(\"Crop box not passed, opening ROI selection tool\")\n",
    "        first_image = open_grey_scale_image(image_list[0])\n",
    "        crop_box = select_rectangle(first_image)\n",
    "\n",
    "    # If show segmentation flag is asserted, display the segmentation of an image\n",
    "    if show_segmentation:\n",
    "        idx_80 = int(len(image_list) * 0.8)\n",
    "        image_80 = crop(open_grey_scale_image(image_list[idx_80]), crop_box)\n",
    "        logging.info(\"Segmentation check requested. Segmenting image %s\", image_list[idx_80])\n",
    "        labeled, _ = segment(image_80)\n",
    "\n",
    "        from skimage.color import label2rgb\n",
    "        overlay_image = label2rgb(labeled, image=image_80, bg_label=1)\n",
    "\n",
    "        import matplotlib\n",
    "        matplotlib.use('Qt4Agg', force=True)\n",
    "        import matplotlib.pyplot as plt\n",
    "        fig = plt.figure()\n",
    "        fig.set_tight_layout(True)\n",
    "        plt.ion()\n",
    "        plt.imshow(overlay_image)\n",
    "        plt.show(block=False)\n",
    "        plt.pause(0.1)\n",
    "\n",
    "        result = input(\"Continue? (y/n)\\n\")\n",
    "\n",
    "        while result != 'y':\n",
    "            if result == 'n':\n",
    "                plt.close()\n",
    "                logging.warning(\"Segmentation rejected. Stopping the application\")\n",
    "                return\n",
    "            else:\n",
    "                result = input(\"Please press 'y' for yes or 'n' for no\\n\")\n",
    "\n",
    "        plt.close()\n",
    "\n",
    "    # Compute the number of batches necessary\n",
    "    num_images = len(image_list)\n",
    "    logging.info(\"Number of images: %d\", num_images)\n",
    "    num_cpu = os.cpu_count()\n",
    "\n",
    "    if num_images < num_cpu:\n",
    "        logging.info(\"Processing on a single thread.\")\n",
    "        flat_data = process_image_batch(image_list, crop_box, model_name, 0, logging.root.level, save_overlay)\n",
    "    else:\n",
    "        logging.info(\"Processing in parallel\")\n",
    "        batch_size = max([1, num_images // (num_cpu-1)])\n",
    "        logging.info(\"Batch size: %d\", batch_size)\n",
    "        num_batches = int(math.ceil(num_images // batch_size))\n",
    "        logging.info(\"Number of batches: %d\", num_batches)\n",
    "\n",
    "        # Process all images from directory in parallel\n",
    "        data = Parallel(n_jobs=-2)(delayed(process_image_batch)(image_list[i*batch_size:min([(i+1)*batch_size, num_images])],\n",
    "                                                                        crop_box,\n",
    "                                                                        model_name,\n",
    "                                                                        i,\n",
    "                                                                        logging.root.level,\n",
    "                                                                        save_overlay)\n",
    "                                    for i in range(num_batches))\n",
    "\n",
    "        flat_data = [item for sublist in data for item in sublist]\n",
    "\n",
    "    # Make a dataframe from the data and save it to disk\n",
    "    df = pd.DataFrame(sorted(flat_data, key=lambda x: x[0]), columns=[\"DateTime\", \"Num drops\", \"Num clear\", \"Num crystal\", \"Image Name\"])\n",
    "    df['RelTime'] = (df['DateTime'] - df['DateTime'][0]).dt.total_seconds()\n",
    "    df.to_csv(os.path.join(directory, \"crystalData.csv\"))\n",
    "    logging.info(\"Saved data to disk.\")\n",
    "\n",
    "    # Plot the data for imediate visualization\n",
    "    if show_plot:\n",
    "        plot_crystal_data(df, directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
